"""
tune_optuna.py

ä½¿ç”¨ Optuna é€²è¡Œè¶…åƒæ•¸è‡ªå‹•åŒ–èª¿å„ª (Hyperparameter Optimization)ã€‚

åŠŸèƒ½ï¼š
1. å®šç¾©å¤šç¶­æœç´¢ç©ºé–“ (åŒ…å« SAC è¶…åƒæ•¸ã€çå‹µæ¬Šé‡ã€æµé‡è² è¼‰)
2. ä½¿ç”¨ TPE Sampler æ™ºèƒ½æ¡æ¨£ + Median Pruner è‡ªå‹•å‰ªæ
3. æ”¯æ´å¤šåŸ·è¡Œç·’å¹³è¡ŒåŒ– (n_jobs)
4. è‡ªå‹•å„²å­˜æœ€ä½³é…ç½® + è¦–è¦ºåŒ–çµæœ

ä½¿ç”¨æ–¹å¼ï¼š
    # å–®åŸ·è¡Œç·’æ¸¬è©¦
    python tune_optuna.py --n-trials 20
    
    # å¹³è¡ŒåŒ–åŸ·è¡Œ (4æ ¸å¿ƒ)
    python tune_optuna.py --n-trials 100 --n-jobs 4
    
    # æŸ¥çœ‹å³æ™‚ Dashboard
    optuna-dashboard sqlite:///optuna_study.db

    # ä½¿ç”¨ nohup åœ¨èƒŒæ™¯åŸ·è¡Œ
    nohup python tune_optuna.py --n-trials 50 --n-jobs 16 > tune_optuna_202602101730.log 2>&1 &

    # æŸ¥çœ‹èƒŒæ™¯åŸ·è¡Œç‹€æ…‹
    ps aux | grep tune_optuna.py

    # åœæ­¢èƒŒæ™¯åŸ·è¡Œ
    pkill -f tune_optuna.py
"""

import copy
import shutil
import yaml
from optuna.pruners import MedianPruner
from optuna.samplers import TPESampler

import os
import argparse
import numpy as np
import optuna
from stable_baselines3 import SAC
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.callbacks import EvalCallback
from src.envs.slicing_env import NetworkSlicingEnv

def prepare_output_paths(args: argparse.Namespace):
    """
    ç¢ºä¿è¼¸å‡ºè³‡æ–™å¤¾èˆ‡æª”æ¡ˆç‚ºä¹¾æ·¨ç‹€æ…‹ï¼š
    - è³‡æ–™å¤¾è‹¥å·²å­˜åœ¨å‰‡åˆªé™¤å¾Œé‡å»º
    - æª”æ¡ˆè‹¥å·²å­˜åœ¨å‰‡åˆªé™¤
    """

    # éœ€è¦å»ºç«‹/é‡å»ºçš„è³‡æ–™å¤¾
    output_dirs = [
        args.optuna_log_dir,
        args.optuna_model_dir,
    ]

    for dir_path in output_dirs:
        if os.path.exists(dir_path):
            if os.path.isdir(dir_path):
                shutil.rmtree(dir_path)
            else:
                os.remove(dir_path)
        os.makedirs(dir_path, exist_ok=True)

    # å¯èƒ½æœƒç”¢ç”Ÿçš„è¼¸å‡ºæª”æ¡ˆï¼ˆå…ˆæ¸…é™¤èˆŠæª”ï¼‰
    output_files = [
        "optuna_history.html",
        "optuna_importance.html",
        "optuna_parallel_coordinate.html",
        "optuna_slice.html",
        "configs/best_config_optuna.yaml",
    ]

    for file_path in output_files:
        if os.path.exists(file_path) and os.path.isfile(file_path):
            os.remove(file_path)

    # Optuna SQLite è³‡æ–™åº«è‹¥å­˜åœ¨å‰‡åˆªé™¤
    if isinstance(args.storage, str) and args.storage.startswith("sqlite:///"):
        db_path = args.storage.replace("sqlite:///", "", 1)
        if db_path and os.path.exists(db_path) and os.path.isfile(db_path):
            os.remove(db_path)

def objective(trial: optuna.Trial, base_config: dict, args: argparse.Namespace):
    """
    Optuna ç›®æ¨™å‡½æ•¸ï¼šåªèª¿æ•´æ¨¡å‹è¶…åƒæ•¸ï¼Œç’°å¢ƒèˆ‡çå‹µæ¬Šé‡å›ºå®šè®€å–è‡ª base_config
    """
    
    # ==========================================
    # 1. å®šç¾©æœç´¢ç©ºé–“ (Search Space) - åƒ…åŒ…å« Agent å¤§è…¦çµæ§‹
    # ==========================================
    
    # --- SAC æ ¸å¿ƒè¶…åƒæ•¸ ---
    # ç¨å¾®ç¸®å° LR ç¯„åœï¼Œé¿å…éå°å°è‡´ä¸æ”¶æ–‚
    learning_rate = trial.suggest_float("learning_rate", 5e-5, 1e-3, log=True) 
    # Gamma é–å®šåœ¨å¥åº·å€é–“
    gamma = trial.suggest_float("gamma", 0.90, 0.995) 
    tau = trial.suggest_float("tau", 0.001, 0.05, log=True)
    
    batch_size = trial.suggest_categorical("batch_size", [128, 256, 512])
    # å¢åŠ  Buffer Size é¸é …ï¼Œæ‡‰å°è¤‡é›œç’°å¢ƒ
    buffer_size = trial.suggest_categorical("buffer_size", [50000, 100000, 200000]) 
    
    # Entropy Coefficient è™•ç†
    ent_coef_mode = trial.suggest_categorical("ent_coef_mode", ["auto", "fixed"])
    if ent_coef_mode == "fixed":
        ent_coef = trial.suggest_float("ent_coef_val", 0.001, 0.5, log=True)
    else:
        ent_coef = "auto"
    
    # --- ç¶²è·¯æ¶æ§‹ (Neural Network Architecture) ---
    n_layers = trial.suggest_int("n_layers", 2, 3)
    
    if n_layers == 2:
        neurons_layer1 = trial.suggest_categorical("neurons_layer1", [128, 256, 512])
        neurons_layer2 = trial.suggest_categorical("neurons_layer2", [128, 256, 512])
        net_arch = [neurons_layer1, neurons_layer2]
    elif n_layers == 3:
        neurons_layer1 = trial.suggest_categorical("neurons_layer1", [128, 256, 512])
        neurons_layer2 = trial.suggest_categorical("neurons_layer2", [128, 256, 512])
        neurons_layer3 = trial.suggest_categorical("neurons_layer3", [128, 256, 512])
        net_arch = [neurons_layer1, neurons_layer2, neurons_layer3]
    
    policy_kwargs = dict(
        net_arch=dict(pi=net_arch, qf=net_arch)
    )
    
    # ==========================================
    # 2. å»ºç«‹ Trial å°ˆå±¬é…ç½®
    # ==========================================
    
    config = copy.deepcopy(base_config)
    config['experiment_name'] = f"optuna_trial_{trial.number}"
    config['random_seed'] = args.seed + trial.number
    
    # å¢åŠ è©•ä¼°é »ç‡èˆ‡æ¬¡æ•¸ï¼Œæ¸›å°‘éš¨æ©Ÿèª¤å·®
    config['eval_freq'] = max(5000, config['total_timesteps'] // 10)
    config['n_eval_episodes'] = 15 
    
    # --- æ›´æ–° Agent è¶…åƒæ•¸ ---
    config['agent']['learning_rate'] = learning_rate
    config['agent']['buffer_size'] = buffer_size
    config['agent']['batch_size'] = batch_size
    config['agent']['gamma'] = gamma
    config['agent']['tau'] = tau
    config['agent']['ent_coef'] = ent_coef # å·²ç¶“è™•ç†é auto/float é‚è¼¯
    
    # è·¯å¾‘è¨­å®š
    config['logging']['log_dir'] = os.path.join(args.optuna_log_dir, f"trial_{trial.number}")
    config['logging']['save_dir'] = os.path.join(args.optuna_model_dir, f"trial_{trial.number}")
    config['logging']['verbose'] = 0
    
    os.makedirs(config['logging']['log_dir'], exist_ok=True)
    os.makedirs(config['logging']['save_dir'], exist_ok=True)
    
    # ==========================================
    # 3. å»ºç«‹ç’°å¢ƒ
    # ==========================================
    
    try:
        train_env = NetworkSlicingEnv(config)
        train_env = Monitor(train_env, filename=os.path.join(config['logging']['log_dir'], "train_monitor"))
        
        eval_env = NetworkSlicingEnv(config)
        eval_env = Monitor(eval_env, filename=os.path.join(config['logging']['log_dir'], "eval_monitor"))
        
    except Exception as e:
        print(f"Trial {trial.number} ç’°å¢ƒå»ºç«‹å¤±æ•—: {e}")
        raise optuna.TrialPruned()
    
    # ==========================================
    # 4. å»ºç«‹ SAC æ¨¡å‹
    # ==========================================
    
    try:
        model = SAC(
            "MlpPolicy",
            train_env,
            learning_rate=learning_rate,
            buffer_size=buffer_size,
            batch_size=batch_size,
            gamma=gamma,
            tau=tau,
            ent_coef=ent_coef, # ç›´æ¥ä½¿ç”¨è™•ç†å¾Œçš„è®Šæ•¸
            policy_kwargs=policy_kwargs,
            verbose=0,
            seed=config['random_seed'],
        )
    except Exception as e:
        print(f"Trial {trial.number} æ¨¡å‹å»ºç«‹å¤±æ•—: {e}")
        train_env.close()
        eval_env.close()
        raise optuna.TrialPruned()
    
    # ==========================================
    # 5. åˆ†æ®µè¨“ç·´ + å‰ªæ (é‚è¼¯ä¿æŒä¸è®Š)
    # ==========================================
    
    eval_callback = EvalCallback(
        eval_env,
        best_model_save_path=config['logging']['save_dir'],
        log_path=config['logging']['log_dir'],
        eval_freq=config['eval_freq'],
        n_eval_episodes=config['n_eval_episodes'],
        deterministic=True,
        render=False,
        verbose=0
    )
    
    try:
        n_checkpoints = 5
        timesteps_per_checkpoint = config['total_timesteps'] // n_checkpoints
        
        for checkpoint in range(n_checkpoints):
            model.learn(
                total_timesteps=timesteps_per_checkpoint,
                callback=eval_callback,
                reset_num_timesteps=False,
                progress_bar=False
            )
            
            # è®€å–è©•ä¼°çµæœ
            eval_log_path = os.path.join(config['logging']['log_dir'], "evaluations.npz")
            if os.path.exists(eval_log_path):
                evaluations = np.load(eval_log_path)
                results = evaluations['results']
                if len(results) > 0:
                    # å–æœ€å¾Œå¹¾æ¬¡çš„å¹³å‡ä½œç‚ºç•¶å‰åˆ†æ•¸
                    current_mean_reward = float(results[-1].mean())
                    trial.report(current_mean_reward, checkpoint)
                    if trial.should_prune():
                        raise optuna.TrialPruned()
        
    except optuna.TrialPruned:
        print(f"Trial {trial.number} Pruned.")
        train_env.close()
        eval_env.close()
        raise
    except Exception as e:
        print(f"Trial {trial.number} Failed: {e}")
        train_env.close()
        eval_env.close()
        raise optuna.TrialPruned()
    
    # ==========================================
    # 6. æå–æœ€çµ‚çµæœ
    # ==========================================
    
    eval_log_path = os.path.join(config['logging']['log_dir'], "evaluations.npz")
    if os.path.exists(eval_log_path):
        evaluations = np.load(eval_log_path)
        results = evaluations['results']
        # å–æœ€å¾Œ 5 æ¬¡è©•ä¼°çš„å¹³å‡ï¼Œæ¯”è¼ƒèƒ½ä»£è¡¨æœ€çµ‚æ”¶æ–‚æ•ˆæœ
        if len(results) >= 5:
            mean_reward = float(results[-5:].mean())
        else:
            mean_reward = float(results.mean())
    else:
        mean_reward = -1e10
    
    train_env.close()
    eval_env.close()
    
    # è¨˜éŒ„é—œéµé…ç½® (åƒ…ä¾›ç´€éŒ„ï¼Œæ–¹ä¾¿æ—¥å¾ŒæŸ¥æ‰¾ç”¨çš„æ˜¯å“ªå€‹æµé‡å ´æ™¯)
    trial.set_user_attr("final_timesteps", config['total_timesteps'])
    # æ³¨æ„ï¼šé€™è£¡æ”¹ç‚ºè¨˜éŒ„ config è£¡çš„å€¼ï¼Œå› ç‚ºå±€éƒ¨è®Šæ•¸å·²ç¶“åˆªé™¤äº†
    if 'traffic' in config:
        trial.set_user_attr("embb_rate", config['traffic'].get('embb_arrival_rate_mbps', 'N/A'))
        trial.set_user_attr("urllc_rate", config['traffic'].get('urllc_arrival_rate_mbps', 'N/A'))
    
    return mean_reward

def main():
    # ==========================================
    # å‘½ä»¤åˆ—åƒæ•¸è§£æ
    # ==========================================
    
    parser = argparse.ArgumentParser(description="Optuna è¶…åƒæ•¸è‡ªå‹•åŒ–èª¿å„ª")
    
    parser.add_argument(
        "--n-trials", 
        type=int, 
        default=50, 
        help="ç¸½è©¦é©—æ¬¡æ•¸ (å»ºè­° 50-200)"
    )
    parser.add_argument(
        "--n-jobs", 
        type=int, 
        default=1, 
        help="å¹³è¡Œå·¥ä½œæ•¸ (å»ºè­°è¨­ç‚º CPU æ ¸å¿ƒæ•¸ï¼Œå¦‚ 4 æˆ– 8)"
    )
    parser.add_argument(
        "--study-name", 
        type=str, 
        default="5g_slicing_sac_v1", 
        help="Study åç¨± (å¯é‡è¤‡ä½¿ç”¨ä»¥ç¹¼çºŒä¸Šæ¬¡çš„æœç´¢)"
    )
    parser.add_argument(
        "--storage", 
        type=str, 
        default="sqlite:///optuna_study.db", 
        help="Optuna è³‡æ–™åº«ä½ç½® (SQLite æˆ– MySQL)"
    )
    parser.add_argument(
        "--config", 
        type=str, 
        default="configs/default_config.yaml", 
        help="åŸºç¤é…ç½®æª”è·¯å¾‘"
    )
    parser.add_argument(
        "--seed", 
        type=int, 
        default=42, 
        help="åŸºç¤éš¨æ©Ÿç¨®å­"
    )
    parser.add_argument(
        "--optuna-log-dir", 
        type=str, 
        default="./optuna_logs", 
        help="Optuna è¨“ç·´æ—¥èªŒæ ¹ç›®éŒ„"
    )
    parser.add_argument(
        "--optuna-model-dir", 
        type=str, 
        default="./optuna_models", 
        help="Optuna æ¨¡å‹å„²å­˜æ ¹ç›®éŒ„"
    )
    parser.add_argument(
        "--timeout", 
        type=int, 
        default=None, 
        help="æœ€å¤§æœç´¢æ™‚é–“ (ç§’)ï¼ŒNone è¡¨ç¤ºä¸é™åˆ¶"
    )
    
    args = parser.parse_args()

    # ==========================================
    # åŸ·è¡Œå‰æ¸…ç†èˆ‡å»ºç«‹è¼¸å‡ºè³‡æ–™å¤¾/æª”æ¡ˆ
    # ==========================================

    prepare_output_paths(args)
    
    # ==========================================
    # è¼‰å…¥åŸºç¤é…ç½®
    # ==========================================
    
    print("=== Optuna è¶…åƒæ•¸èª¿å„ªé–‹å§‹ ===\n")
    print(f"åŸºç¤é…ç½®: {args.config}")
    print(f"ç¸½è©¦é©—æ¬¡æ•¸: {args.n_trials}")
    print(f"å¹³è¡Œå·¥ä½œæ•¸: {args.n_jobs}")
    print(f"Study åç¨±: {args.study_name}")
    print(f"è³‡æ–™åº«: {args.storage}\n")
    
    if not os.path.exists(args.config):
        raise FileNotFoundError(f"é…ç½®æª”ä¸å­˜åœ¨: {args.config}")
    
    with open(args.config, 'r', encoding='utf-8') as f:
        base_config = yaml.safe_load(f)
    
    # å»ºç«‹è¼¸å‡ºç›®éŒ„
    os.makedirs(args.optuna_log_dir, exist_ok=True)
    os.makedirs(args.optuna_model_dir, exist_ok=True)
    
    # ==========================================
    # å»ºç«‹ Optuna Study
    # ==========================================
    
    study = optuna.create_study(
        study_name=args.study_name,
        storage=args.storage,
        load_if_exists=True,  # å…è¨±ç¹¼çºŒä¹‹å‰çš„æœç´¢
        direction="maximize",  # æœ€å¤§åŒ– mean_reward
        sampler=TPESampler(
            seed=args.seed,
            n_startup_trials=10,  # å‰ 10 å€‹ trial ç”¨éš¨æ©Ÿæ¡æ¨£ (warm-up)
            multivariate=True  # è€ƒæ…®åƒæ•¸é–“çš„ç›¸é—œæ€§
        ),
        pruner=MedianPruner(
            n_startup_trials=5,  # å‰ 5 å€‹ trial ä¸å‰ªæ
            n_warmup_steps=5,    # è©•ä¼° 5 æ¬¡å¾Œæ‰é–‹å§‹å‰ªæ
            interval_steps=1     # æ¯æ¬¡è©•ä¼°å¾Œéƒ½æª¢æŸ¥æ˜¯å¦è¦å‰ªæ
        )
    )
    
    # ==========================================
    # é–‹å§‹å„ªåŒ–
    # ==========================================
    
    print("é–‹å§‹æœç´¢æœ€ä½³è¶…åƒæ•¸...\n")
    
    study.optimize(
        lambda trial: objective(trial, base_config, args),
        n_trials=args.n_trials,
        n_jobs=args.n_jobs,
        timeout=args.timeout,
        show_progress_bar=True,
        catch=(Exception,)  # æ•æ‰ç•°å¸¸ä½†ç¹¼çºŒåŸ·è¡Œå…¶ä»– trials
    )
    
    # ==========================================
    # è¼¸å‡ºçµæœ
    # ==========================================
    
    print("\n" + "="*60)
    print("=== å„ªåŒ–å®Œæˆ ===")
    print("="*60 + "\n")
    
    print(f"å®Œæˆçš„ Trials æ•¸é‡: {len(study.trials)}")
    print(f"è¢«å‰ªæçš„ Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}")
    print(f"å¤±æ•—çš„ Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}")
    print(f"æˆåŠŸçš„ Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}\n")
    
    if len(study.best_trials) > 0:
        print(f"ğŸ† æœ€ä½³ Trial: #{study.best_trial.number}")
        print(f"ğŸ† æœ€ä½³ Mean Reward: {study.best_value:.2f}\n")
        
        print("æœ€ä½³è¶…åƒæ•¸:")
        print("-" * 60)
        for key, value in study.best_params.items():
            print(f"  {key:30s}: {value}")
        print("-" * 60 + "\n")
        
        # ==========================================
        # å„²å­˜æœ€ä½³é…ç½®
        # ==========================================
        
        best_config_path = "configs/best_config_optuna.yaml"
        
        # å»ºç«‹å®Œæ•´çš„é…ç½®æª” (åŒ…å«æœ€ä½³è¶…åƒæ•¸)
        final_config = base_config.copy()
        
        # æ›´æ–° Agent è¶…åƒæ•¸
        final_config['agent']['learning_rate'] = study.best_params['learning_rate']
        final_config['agent']['buffer_size'] = study.best_params['buffer_size']
        final_config['agent']['batch_size'] = study.best_params['batch_size']
        final_config['agent']['gamma'] = study.best_params['gamma']
        final_config['agent']['tau'] = study.best_params['tau']
        if study.best_params['ent_coef_mode'] == 'auto':
            final_config['agent']['ent_coef'] = 'auto'
        else:
            final_config['agent']['ent_coef'] = study.best_params['ent_coef_val']
        
        # æ›´æ–°ç¥ç¶“ç¶²è·¯æ¶æ§‹
        n_layers = study.best_params['n_layers']
        net_arch = []
        for i in range(1, n_layers + 1):
            layer_key = f'neurons_layer{i}'
            if layer_key in study.best_params:
                net_arch.append(study.best_params[layer_key])
        
        # å„²å­˜ç¶²è·¯æ¶æ§‹åˆ°é…ç½®æª”
        if 'policy_kwargs' not in final_config['agent']:
            final_config['agent']['policy_kwargs'] = {}
        final_config['agent']['policy_kwargs']['net_arch'] = {
            'pi': net_arch,  # Actor ç¶²è·¯
            'qf': net_arch   # Critic ç¶²è·¯
        }
        
        # å„²å­˜åˆ° YAML
        with open(best_config_path, 'w', encoding='utf-8') as f:
            yaml.dump(final_config, f, default_flow_style=False, allow_unicode=True)
        
        print(f"âœ… æœ€ä½³é…ç½®å·²å„²å­˜è‡³: {best_config_path}")
        print(f"   å¯ä½¿ç”¨ä»¥ä¸‹æŒ‡ä»¤é€²è¡Œå®Œæ•´è¨“ç·´:")
        print(f"   python main.py --config {best_config_path}\n")
        
    else:
        print("âš ï¸  æ²’æœ‰æˆåŠŸå®Œæˆçš„ Trialsï¼Œè«‹æª¢æŸ¥é…ç½®æˆ–é™ä½ timesteps")
    
    # ==========================================
    # è¦–è¦ºåŒ–çµæœ (éœ€è¦ plotly)
    # ==========================================
    
    try:
        import plotly
        
        print("ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨...")
        
        # 1. å„ªåŒ–æ­·å²
        fig_history = optuna.visualization.plot_optimization_history(study)
        fig_history.write_html("optuna_history.html")
        
        # 2. åƒæ•¸é‡è¦æ€§
        if len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]) >= 10:
            fig_importance = optuna.visualization.plot_param_importances(study)
            fig_importance.write_html("optuna_importance.html")
        
        # 3. è¶…åƒæ•¸é—œä¿‚ (Parallel Coordinate)
        fig_parallel = optuna.visualization.plot_parallel_coordinate(study)
        fig_parallel.write_html("optuna_parallel_coordinate.html")
        
        # 4. Slice Plot (æ¯å€‹åƒæ•¸çš„å½±éŸ¿)
        fig_slice = optuna.visualization.plot_slice(study)
        fig_slice.write_html("optuna_slice.html")
        
        print("âœ… è¦–è¦ºåŒ–çµæœå·²å„²å­˜:")
        print("   - optuna_history.html (å„ªåŒ–æ­·å²)")
        print("   - optuna_importance.html (åƒæ•¸é‡è¦æ€§)")
        print("   - optuna_parallel_coordinate.html (åƒæ•¸é—œä¿‚)")
        print("   - optuna_slice.html (åƒæ•¸å½±éŸ¿)\n")
        
    except ImportError:
        print("âš ï¸  æœªå®‰è£ plotlyï¼Œè·³éè¦–è¦ºåŒ–")
        print("   å®‰è£æ–¹å¼: pip install plotly\n")
    
    # ==========================================
    # è¼¸å‡º Dashboard æŒ‡ä»¤
    # ==========================================
    
    print("="*60)
    print("ğŸ’¡ æç¤ºï¼šä½¿ç”¨ä»¥ä¸‹æŒ‡ä»¤æŸ¥çœ‹å³æ™‚ Dashboard:")
    print(f"   optuna-dashboard {args.storage}")
    print("   (éœ€å…ˆå®‰è£: pip install optuna-dashboard)")
    print("="*60 + "\n")


if __name__ == "__main__":
    main()
