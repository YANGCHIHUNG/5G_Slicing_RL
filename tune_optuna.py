"""
tune_optuna.py

ä½¿ç”¨ Optuna é€²è¡Œè¶…åƒæ•¸è‡ªå‹•åŒ–èª¿å„ª (Hyperparameter Optimization)ã€‚

åŠŸèƒ½ï¼š
1. å®šç¾©å¤šç¶­æœç´¢ç©ºé–“ (åŒ…å« SAC è¶…åƒæ•¸ã€çå‹µæ¬Šé‡ã€æµé‡è² è¼‰)
2. ä½¿ç”¨ TPE Sampler æ™ºèƒ½æ¡æ¨£ + Median Pruner è‡ªå‹•å‰ªæ
3. æ”¯æ´å¤šåŸ·è¡Œç·’å¹³è¡ŒåŒ– (n_jobs)
4. è‡ªå‹•å„²å­˜æœ€ä½³é…ç½® + è¦–è¦ºåŒ–çµæœ

ä½¿ç”¨æ–¹å¼ï¼š
    # å–®åŸ·è¡Œç·’æ¸¬è©¦
    python tune_optuna.py --n-trials 20
    
    # å¹³è¡ŒåŒ–åŸ·è¡Œ (4æ ¸å¿ƒ)
    python tune_optuna.py --n-trials 100 --n-jobs 4
    
    # æŸ¥çœ‹å³æ™‚ Dashboard
    optuna-dashboard sqlite:///optuna_study.db
"""

import os
import yaml
import argparse
import numpy as np
import optuna
from optuna.pruners import MedianPruner
from optuna.samplers import TPESampler

from stable_baselines3 import SAC
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.callbacks import EvalCallback

from src.envs.slicing_env import NetworkSlicingEnv


def objective(trial: optuna.Trial, base_config: dict, args: argparse.Namespace):
    """
    Optuna ç›®æ¨™å‡½æ•¸ï¼šè¨“ç·´ä¸€å€‹ SAC Agent ä¸¦è¿”å›è©•ä¼°çå‹µ
    
    Args:
        trial: Optuna Trial ç‰©ä»¶
        base_config: åŸºç¤é…ç½®æª” (ä¾†è‡ª default_config.yaml)
        args: å‘½ä»¤åˆ—åƒæ•¸
        
    Returns:
        float: è©•ä¼°éšæ®µçš„å¹³å‡çå‹µ (mean_reward)
    """
    
    # ==========================================
    # 1. å®šç¾©æœç´¢ç©ºé–“ (Search Space)
    # ==========================================
    
    # --- SAC æ ¸å¿ƒè¶…åƒæ•¸ ---
    learning_rate = trial.suggest_float("learning_rate", 1e-5, 1e-3, log=True)
    gamma = trial.suggest_float("gamma", 0.95, 0.9999)
    tau = trial.suggest_float("tau", 0.001, 0.02, log=True)
    ent_coef = trial.suggest_categorical("ent_coef", ["auto", "auto_0.1", "auto_0.01"])
    batch_size = trial.suggest_categorical("batch_size", [64, 128, 256, 512])
    buffer_size = trial.suggest_categorical("buffer_size", [10000, 30000, 50000, 100000])
    
    # --- ç¶²è·¯æ¶æ§‹ ---
    # æœç´¢ç¥ç¶“ç¶²è·¯å±¤æ•¸èˆ‡ç¥ç¶“å…ƒæ•¸
    n_layers = trial.suggest_int("n_layers", 2, 4)  # 2-4 å±¤éš±è—å±¤
    
    # ç‚ºæ¯ä¸€å±¤é¸æ“‡ç¥ç¶“å…ƒæ•¸ï¼ˆå¯ä»¥ä¸åŒï¼‰
    if n_layers == 2:
        neurons_layer1 = trial.suggest_categorical("neurons_layer1", [64, 128, 256, 512])
        neurons_layer2 = trial.suggest_categorical("neurons_layer2", [64, 128, 256, 512])
        net_arch = [neurons_layer1, neurons_layer2]
    elif n_layers == 3:
        neurons_layer1 = trial.suggest_categorical("neurons_layer1", [64, 128, 256, 512])
        neurons_layer2 = trial.suggest_categorical("neurons_layer2", [64, 128, 256, 512])
        neurons_layer3 = trial.suggest_categorical("neurons_layer3", [64, 128, 256, 512])
        net_arch = [neurons_layer1, neurons_layer2, neurons_layer3]
    else:  # n_layers == 4
        neurons_layer1 = trial.suggest_categorical("neurons_layer1", [64, 128, 256, 512])
        neurons_layer2 = trial.suggest_categorical("neurons_layer2", [64, 128, 256, 512])
        neurons_layer3 = trial.suggest_categorical("neurons_layer3", [64, 128, 256, 512])
        neurons_layer4 = trial.suggest_categorical("neurons_layer4", [64, 128, 256, 512])
        net_arch = [neurons_layer1, neurons_layer2, neurons_layer3, neurons_layer4]
    
    # å»ºç«‹ policy_kwargs
    policy_kwargs = dict(
        net_arch=dict(
            pi=net_arch,  # Actor ç¶²è·¯æ¶æ§‹
            qf=net_arch   # Critic ç¶²è·¯æ¶æ§‹ï¼ˆQ-functionï¼‰
        )
    )
    
    # --- çå‹µå‡½æ•¸æ¬Šé‡ ---
    w_throughput = trial.suggest_float("w_throughput", 0.01, 2.0, log=True)
    w_latency = trial.suggest_float("w_latency", 10.0, 300.0, log=True)
    drop_penalty = trial.suggest_float("drop_penalty", 10.0, 500.0, log=True)
    
    # --- æµé‡è² è¼‰å ´æ™¯ ---
    embb_rate = trial.suggest_float("embb_arrival_rate_mbps", 50.0, 250.0)
    urllc_rate = trial.suggest_float("urllc_arrival_rate_mbps", 2.0, 25.0)
    
    # --- ç’°å¢ƒè¨­å®š ---
    env_max_steps = trial.suggest_categorical("env_max_steps", [1000, 2000, 3000, 5000])
    min_rbs_urllc = trial.suggest_int("min_rbs_urllc", 0, 40)
    normalize_obs = trial.suggest_categorical("normalize_obs", [True, False])
    
    # ==========================================
    # 2. å»ºç«‹ Trial å°ˆå±¬é…ç½®
    # ==========================================
    
    config = base_config.copy()
    config['experiment_name'] = f"optuna_trial_{trial.number}"
    config['random_seed'] = args.seed + trial.number  # æ¯å€‹ trial ä¸åŒ seed
    config['total_timesteps'] = args.timesteps  # ä½¿ç”¨ç¸®çŸ­çš„è¨“ç·´æ­¥æ•¸åŠ é€Ÿæœç´¢
    config['eval_freq'] = max(2000, args.timesteps // 10)  # è‡³å°‘è©•ä¼° 10 æ¬¡
    config['n_eval_episodes'] = 5  # æ¸›å°‘è©•ä¼° episodes åŠ é€Ÿ
    
    # æ›´æ–°æœç´¢åˆ°çš„è¶…åƒæ•¸
    config['agent']['learning_rate'] = learning_rate
    config['agent']['buffer_size'] = buffer_size
    config['agent']['batch_size'] = batch_size
    config['agent']['gamma'] = gamma
    config['agent']['tau'] = tau
    
    # è™•ç† ent_coef (Optuna ä¸æ”¯æ´ç›´æ¥ suggest "auto"ï¼Œéœ€è½‰æ›)
    if ent_coef == "auto":
        config['agent']['ent_coef'] = "auto"
    elif ent_coef == "auto_0.1":
        config['agent']['ent_coef'] = "auto_0.1"
    elif ent_coef == "auto_0.01":
        config['agent']['ent_coef'] = "auto_0.01"
    else:
        config['agent']['ent_coef'] = float(ent_coef)
    
    config['reward']['w_throughput'] = w_throughput
    config['reward']['w_latency'] = w_latency
    config['reward']['drop_penalty'] = drop_penalty
    
    config['traffic']['embb_arrival_rate_mbps'] = embb_rate
    config['traffic']['urllc_arrival_rate_mbps'] = urllc_rate
    
    # ç’°å¢ƒè¨­å®š (å¦‚æœ base_config æ²’æœ‰ 'env' keyï¼Œå»ºç«‹å®ƒ)
    if 'env' not in config:
        config['env'] = {}
    config['env']['env_max_steps'] = env_max_steps
    config['env']['min_rbs_urllc'] = min_rbs_urllc
    config['env']['normalize_obs'] = normalize_obs
    
    # è·¯å¾‘è¨­å®š
    config['logging']['log_dir'] = os.path.join(args.optuna_log_dir, f"trial_{trial.number}")
    config['logging']['save_dir'] = os.path.join(args.optuna_model_dir, f"trial_{trial.number}")
    config['logging']['verbose'] = 0  # æ¸›å°‘è¼¸å‡º
    
    # å»ºç«‹ç›®éŒ„
    os.makedirs(config['logging']['log_dir'], exist_ok=True)
    os.makedirs(config['logging']['save_dir'], exist_ok=True)
    
    # ==========================================
    # 3. å»ºç«‹ç’°å¢ƒ
    # ==========================================
    
    try:
        train_env = NetworkSlicingEnv(config)
        train_env = Monitor(
            train_env, 
            filename=os.path.join(config['logging']['log_dir'], "train_monitor"),
            allow_early_resets=True
        )
        
        eval_env = NetworkSlicingEnv(config)
        eval_env = Monitor(
            eval_env,
            filename=os.path.join(config['logging']['log_dir'], "eval_monitor"),
            allow_early_resets=True
        )
        
    except Exception as e:
        print(f"Trial {trial.number} ç’°å¢ƒå»ºç«‹å¤±æ•—: {e}")
        raise optuna.TrialPruned()
    
    # ==========================================
    # 4. å»ºç«‹ SAC æ¨¡å‹
    # ==========================================
    
    try:
        model = SAC(
            "MlpPolicy",
            train_env,
            learning_rate=learning_rate,
            buffer_size=buffer_size,
            batch_size=batch_size,
            gamma=gamma,
            tau=tau,
            ent_coef=config['agent']['ent_coef'],
            policy_kwargs=policy_kwargs,  # ä½¿ç”¨è‡ªå®šç¾©ç¶²è·¯æ¶æ§‹
            verbose=0,
            seed=config['random_seed'],
            tensorboard_log=None  # ä¸ä½¿ç”¨ TensorBoard ç¯€çœç©ºé–“
        )
    except Exception as e:
        print(f"Trial {trial.number} æ¨¡å‹å»ºç«‹å¤±æ•—: {e}")
        train_env.close()
        eval_env.close()
        raise optuna.TrialPruned()
    
    # ==========================================
    # 5. å»ºç«‹ Callbacks
    # ==========================================
    
    # è©•ä¼° Callback
    eval_callback = EvalCallback(
        eval_env,
        best_model_save_path=config['logging']['save_dir'],
        log_path=config['logging']['log_dir'],
        eval_freq=config['eval_freq'],
        n_eval_episodes=config['n_eval_episodes'],
        deterministic=True,
        render=False,
        verbose=0
    )
    
    # ==========================================
    # 6. åˆ†æ®µè¨“ç·´ + æ‰‹å‹•å‰ªæ
    # ==========================================
    
    try:
        # å°‡è¨“ç·´åˆ†æˆå¤šå€‹éšæ®µï¼Œæ¯å€‹éšæ®µå¾Œæª¢æŸ¥æ˜¯å¦è¦å‰ªæ
        n_checkpoints = 5
        timesteps_per_checkpoint = config['total_timesteps'] // n_checkpoints
        
        for checkpoint in range(n_checkpoints):
            # è¨“ç·´ä¸€æ®µæ™‚é–“
            model.learn(
                total_timesteps=timesteps_per_checkpoint,
                callback=eval_callback,
                reset_num_timesteps=False,
                progress_bar=False
            )
            
            # è®€å–ç•¶å‰è©•ä¼°çµæœ
            eval_log_path = os.path.join(config['logging']['log_dir'], "evaluations.npz")
            if os.path.exists(eval_log_path):
                evaluations = np.load(eval_log_path)
                results = evaluations['results']
                if len(results) > 0:
                    current_mean_reward = float(results[-1].mean())
                    
                    # å›å ±çµ¦ Optuna
                    trial.report(current_mean_reward, checkpoint)
                    
                    # æª¢æŸ¥æ˜¯å¦è¦å‰ªæ
                    if trial.should_prune():
                        raise optuna.TrialPruned()
        
    except optuna.TrialPruned:
        print(f"Trial {trial.number} è¢«å‰ªæ (Pruned) at checkpoint {checkpoint}/{n_checkpoints}")
        train_env.close()
        eval_env.close()
        raise
    except Exception as e:
        print(f"Trial {trial.number} è¨“ç·´å¤±æ•—: {e}")
        train_env.close()
        eval_env.close()
        raise optuna.TrialPruned()
    
    # ==========================================
    # 7. æå–è©•ä¼°çµæœ
    # ==========================================
    
    # å¾ evaluations.npz è®€å–æœ€çµ‚è©•ä¼°çå‹µ
    eval_log_path = os.path.join(config['logging']['log_dir'], "evaluations.npz")
    
    if os.path.exists(eval_log_path):
        try:
            evaluations = np.load(eval_log_path)
            # å–æœ€å¾Œå¹¾æ¬¡è©•ä¼°çš„å¹³å‡å€¼ (æ›´ç©©å®š)
            results = evaluations['results']
            if len(results) >= 3:
                mean_reward = float(results[-3:].mean())  # æœ€å¾Œ 3 æ¬¡è©•ä¼°çš„å¹³å‡
            else:
                mean_reward = float(results.mean())
        except Exception as e:
            print(f"Trial {trial.number} è®€å–è©•ä¼°çµæœå¤±æ•—: {e}")
            mean_reward = -1e10  # çµ¦äºˆæ¥µå·®çš„åˆ†æ•¸
    else:
        print(f"Trial {trial.number} æ²’æœ‰æ‰¾åˆ°è©•ä¼°æ—¥èªŒ")
        mean_reward = -1e10
    
    # ==========================================
    # 8. æ¸…ç†è³‡æº
    # ==========================================
    
    train_env.close()
    eval_env.close()
    
    # è¨˜éŒ„é¡å¤–è³‡è¨Šåˆ° Trial (ä¾›å¾ŒçºŒåˆ†æ)
    trial.set_user_attr("final_timesteps", config['total_timesteps'])
    trial.set_user_attr("embb_rate", embb_rate)
    trial.set_user_attr("urllc_rate", urllc_rate)
    
    return mean_reward


def main():
    # ==========================================
    # å‘½ä»¤åˆ—åƒæ•¸è§£æ
    # ==========================================
    
    parser = argparse.ArgumentParser(description="Optuna è¶…åƒæ•¸è‡ªå‹•åŒ–èª¿å„ª")
    
    parser.add_argument(
        "--n-trials", 
        type=int, 
        default=50, 
        help="ç¸½è©¦é©—æ¬¡æ•¸ (å»ºè­° 50-200)"
    )
    parser.add_argument(
        "--n-jobs", 
        type=int, 
        default=1, 
        help="å¹³è¡Œå·¥ä½œæ•¸ (å»ºè­°è¨­ç‚º CPU æ ¸å¿ƒæ•¸ï¼Œå¦‚ 4 æˆ– 8)"
    )
    parser.add_argument(
        "--timesteps", 
        type=int, 
        default=50000, 
        help="æ¯å€‹ trial çš„è¨“ç·´æ­¥æ•¸ (ç¸®çŸ­ä»¥åŠ é€Ÿæœç´¢ï¼Œå»ºè­° 30k-100k)"
    )
    parser.add_argument(
        "--study-name", 
        type=str, 
        default="5g_slicing_sac_v1", 
        help="Study åç¨± (å¯é‡è¤‡ä½¿ç”¨ä»¥ç¹¼çºŒä¸Šæ¬¡çš„æœç´¢)"
    )
    parser.add_argument(
        "--storage", 
        type=str, 
        default="sqlite:///optuna_study.db", 
        help="Optuna è³‡æ–™åº«ä½ç½® (SQLite æˆ– MySQL)"
    )
    parser.add_argument(
        "--config", 
        type=str, 
        default="configs/default_config.yaml", 
        help="åŸºç¤é…ç½®æª”è·¯å¾‘"
    )
    parser.add_argument(
        "--seed", 
        type=int, 
        default=42, 
        help="åŸºç¤éš¨æ©Ÿç¨®å­"
    )
    parser.add_argument(
        "--optuna-log-dir", 
        type=str, 
        default="./optuna_logs", 
        help="Optuna è¨“ç·´æ—¥èªŒæ ¹ç›®éŒ„"
    )
    parser.add_argument(
        "--optuna-model-dir", 
        type=str, 
        default="./optuna_models", 
        help="Optuna æ¨¡å‹å„²å­˜æ ¹ç›®éŒ„"
    )
    parser.add_argument(
        "--timeout", 
        type=int, 
        default=None, 
        help="æœ€å¤§æœç´¢æ™‚é–“ (ç§’)ï¼ŒNone è¡¨ç¤ºä¸é™åˆ¶"
    )
    
    args = parser.parse_args()
    
    # ==========================================
    # è¼‰å…¥åŸºç¤é…ç½®
    # ==========================================
    
    print("=== Optuna è¶…åƒæ•¸èª¿å„ªé–‹å§‹ ===\n")
    print(f"åŸºç¤é…ç½®: {args.config}")
    print(f"ç¸½è©¦é©—æ¬¡æ•¸: {args.n_trials}")
    print(f"å¹³è¡Œå·¥ä½œæ•¸: {args.n_jobs}")
    print(f"æ¯å€‹ Trial è¨“ç·´æ­¥æ•¸: {args.timesteps}")
    print(f"Study åç¨±: {args.study_name}")
    print(f"è³‡æ–™åº«: {args.storage}\n")
    
    if not os.path.exists(args.config):
        raise FileNotFoundError(f"é…ç½®æª”ä¸å­˜åœ¨: {args.config}")
    
    with open(args.config, 'r', encoding='utf-8') as f:
        base_config = yaml.safe_load(f)
    
    # å»ºç«‹è¼¸å‡ºç›®éŒ„
    os.makedirs(args.optuna_log_dir, exist_ok=True)
    os.makedirs(args.optuna_model_dir, exist_ok=True)
    
    # ==========================================
    # å»ºç«‹ Optuna Study
    # ==========================================
    
    study = optuna.create_study(
        study_name=args.study_name,
        storage=args.storage,
        load_if_exists=True,  # å…è¨±ç¹¼çºŒä¹‹å‰çš„æœç´¢
        direction="maximize",  # æœ€å¤§åŒ– mean_reward
        sampler=TPESampler(
            seed=args.seed,
            n_startup_trials=10,  # å‰ 10 å€‹ trial ç”¨éš¨æ©Ÿæ¡æ¨£ (warm-up)
            multivariate=True  # è€ƒæ…®åƒæ•¸é–“çš„ç›¸é—œæ€§
        ),
        pruner=MedianPruner(
            n_startup_trials=5,  # å‰ 5 å€‹ trial ä¸å‰ªæ
            n_warmup_steps=5,    # è©•ä¼° 5 æ¬¡å¾Œæ‰é–‹å§‹å‰ªæ
            interval_steps=1     # æ¯æ¬¡è©•ä¼°å¾Œéƒ½æª¢æŸ¥æ˜¯å¦è¦å‰ªæ
        )
    )
    
    # ==========================================
    # é–‹å§‹å„ªåŒ–
    # ==========================================
    
    print("é–‹å§‹æœç´¢æœ€ä½³è¶…åƒæ•¸...\n")
    
    study.optimize(
        lambda trial: objective(trial, base_config, args),
        n_trials=args.n_trials,
        n_jobs=args.n_jobs,
        timeout=args.timeout,
        show_progress_bar=True,
        catch=(Exception,)  # æ•æ‰ç•°å¸¸ä½†ç¹¼çºŒåŸ·è¡Œå…¶ä»– trials
    )
    
    # ==========================================
    # è¼¸å‡ºçµæœ
    # ==========================================
    
    print("\n" + "="*60)
    print("=== å„ªåŒ–å®Œæˆ ===")
    print("="*60 + "\n")
    
    print(f"å®Œæˆçš„ Trials æ•¸é‡: {len(study.trials)}")
    print(f"è¢«å‰ªæçš„ Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}")
    print(f"å¤±æ•—çš„ Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}")
    print(f"æˆåŠŸçš„ Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}\n")
    
    if len(study.best_trials) > 0:
        print(f"ğŸ† æœ€ä½³ Trial: #{study.best_trial.number}")
        print(f"ğŸ† æœ€ä½³ Mean Reward: {study.best_value:.2f}\n")
        
        print("æœ€ä½³è¶…åƒæ•¸:")
        print("-" * 60)
        for key, value in study.best_params.items():
            print(f"  {key:30s}: {value}")
        print("-" * 60 + "\n")
        
        # ==========================================
        # å„²å­˜æœ€ä½³é…ç½®
        # ==========================================
        
        best_config_path = "configs/best_config_optuna.yaml"
        
        # å»ºç«‹å®Œæ•´çš„é…ç½®æª” (åŒ…å«æœ€ä½³è¶…åƒæ•¸)
        final_config = base_config.copy()
        
        # æ›´æ–° Agent è¶…åƒæ•¸
        final_config['agent']['learning_rate'] = study.best_params['learning_rate']
        final_config['agent']['buffer_size'] = study.best_params['buffer_size']
        final_config['agent']['batch_size'] = study.best_params['batch_size']
        final_config['agent']['gamma'] = study.best_params['gamma']
        final_config['agent']['tau'] = study.best_params['tau']
        final_config['agent']['ent_coef'] = study.best_params['ent_coef']
        
        # æ›´æ–°ç¥ç¶“ç¶²è·¯æ¶æ§‹
        n_layers = study.best_params['n_layers']
        net_arch = []
        for i in range(1, n_layers + 1):
            layer_key = f'neurons_layer{i}'
            if layer_key in study.best_params:
                net_arch.append(study.best_params[layer_key])
        
        # å„²å­˜ç¶²è·¯æ¶æ§‹åˆ°é…ç½®æª”
        if 'policy_kwargs' not in final_config['agent']:
            final_config['agent']['policy_kwargs'] = {}
        final_config['agent']['policy_kwargs']['net_arch'] = {
            'pi': net_arch,  # Actor ç¶²è·¯
            'qf': net_arch   # Critic ç¶²è·¯
        }
        
        # æ›´æ–° Reward æ¬Šé‡
        final_config['reward']['w_throughput'] = study.best_params['w_throughput']
        final_config['reward']['w_latency'] = study.best_params['w_latency']
        final_config['reward']['drop_penalty'] = study.best_params['drop_penalty']
        
        # æ›´æ–°æµé‡å ´æ™¯
        final_config['traffic']['embb_arrival_rate_mbps'] = study.best_params['embb_arrival_rate_mbps']
        final_config['traffic']['urllc_arrival_rate_mbps'] = study.best_params['urllc_arrival_rate_mbps']
        
        # æ›´æ–°ç’°å¢ƒè¨­å®š
        if 'env' not in final_config:
            final_config['env'] = {}
        final_config['env']['env_max_steps'] = study.best_params['env_max_steps']
        final_config['env']['min_rbs_urllc'] = study.best_params['min_rbs_urllc']
        final_config['env']['normalize_obs'] = study.best_params['normalize_obs']
        
        # å„²å­˜åˆ° YAML
        with open(best_config_path, 'w', encoding='utf-8') as f:
            yaml.dump(final_config, f, default_flow_style=False, allow_unicode=True)
        
        print(f"âœ… æœ€ä½³é…ç½®å·²å„²å­˜è‡³: {best_config_path}")
        print(f"   å¯ä½¿ç”¨ä»¥ä¸‹æŒ‡ä»¤é€²è¡Œå®Œæ•´è¨“ç·´:")
        print(f"   python main.py --config {best_config_path}\n")
        
    else:
        print("âš ï¸  æ²’æœ‰æˆåŠŸå®Œæˆçš„ Trialsï¼Œè«‹æª¢æŸ¥é…ç½®æˆ–é™ä½ timesteps")
    
    # ==========================================
    # è¦–è¦ºåŒ–çµæœ (éœ€è¦ plotly)
    # ==========================================
    
    try:
        import plotly
        
        print("ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨...")
        
        # 1. å„ªåŒ–æ­·å²
        fig_history = optuna.visualization.plot_optimization_history(study)
        fig_history.write_html("optuna_history.html")
        
        # 2. åƒæ•¸é‡è¦æ€§
        if len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]) >= 10:
            fig_importance = optuna.visualization.plot_param_importances(study)
            fig_importance.write_html("optuna_importance.html")
        
        # 3. è¶…åƒæ•¸é—œä¿‚ (Parallel Coordinate)
        fig_parallel = optuna.visualization.plot_parallel_coordinate(study)
        fig_parallel.write_html("optuna_parallel_coordinate.html")
        
        # 4. Slice Plot (æ¯å€‹åƒæ•¸çš„å½±éŸ¿)
        fig_slice = optuna.visualization.plot_slice(study)
        fig_slice.write_html("optuna_slice.html")
        
        print("âœ… è¦–è¦ºåŒ–çµæœå·²å„²å­˜:")
        print("   - optuna_history.html (å„ªåŒ–æ­·å²)")
        print("   - optuna_importance.html (åƒæ•¸é‡è¦æ€§)")
        print("   - optuna_parallel_coordinate.html (åƒæ•¸é—œä¿‚)")
        print("   - optuna_slice.html (åƒæ•¸å½±éŸ¿)\n")
        
    except ImportError:
        print("âš ï¸  æœªå®‰è£ plotlyï¼Œè·³éè¦–è¦ºåŒ–")
        print("   å®‰è£æ–¹å¼: pip install plotly\n")
    
    # ==========================================
    # è¼¸å‡º Dashboard æŒ‡ä»¤
    # ==========================================
    
    print("="*60)
    print("ğŸ’¡ æç¤ºï¼šä½¿ç”¨ä»¥ä¸‹æŒ‡ä»¤æŸ¥çœ‹å³æ™‚ Dashboard:")
    print(f"   optuna-dashboard {args.storage}")
    print("   (éœ€å…ˆå®‰è£: pip install optuna-dashboard)")
    print("="*60 + "\n")


if __name__ == "__main__":
    main()
